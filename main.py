#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šä¸»ä½“å»ºæ¨¡å®éªŒä¸»ç¨‹åº
ç”¨äºå¯¹æ¯”INFPå’ŒESTPä¸¤ç§é¢†å¯¼è€…ç±»å‹åœ¨ç¾¤ä½“åä½œä¸­çš„è¡¨ç°å·®å¼‚
"""

import sys
import os
from pathlib import Path
import argparse
import json
import time
from datetime import datetime
import matplotlib.pyplot as plt

# ç¡®ä¿ä¸­æ–‡å­—ä½“æ­£ç¡®æ˜¾ç¤ºï¼ˆä¸demo.pyä¿æŒä¸€è‡´ï¼‰
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from simulation import Simulation, SimulationConfig
from analysis import ResultAnalyzer

def print_banner():
    """æ‰“å°ç¨‹åºæ ‡é¢˜"""
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                    å¤šä¸»ä½“å»ºæ¨¡å®éªŒç³»ç»Ÿ                           â•‘
    â•‘                Agent-Based Modeling for Leadership            â•‘
    â•‘                                                               â•‘
    â•‘    å¯¹æ¯”åˆ†æINFPä¸ESTPé¢†å¯¼è€…åœ¨ç¾¤ä½“åä½œä¸­çš„è¡¨ç°å·®å¼‚               â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)

def create_experiment_config():
    """åˆ›å»ºå®éªŒé…ç½®"""
    print("\n=== å®éªŒé…ç½® ===")
    
    # é»˜è®¤é…ç½®
    default_config = {
        'team_size': 8,  # å¢åŠ å›¢é˜Ÿè§„æ¨¡ä»¥å¢åŠ å¤æ‚æ€§
        'max_rounds': 30,  # å¢åŠ è½®æ¬¡
        'task_complexity': 3.0,  # æ˜¾è‘—æé«˜å¤æ‚åº¦
        'external_pressure': 0.3,
        'random_seed': 42
    }
    
    print("ä½¿ç”¨é»˜è®¤é…ç½®è¿˜æ˜¯è‡ªå®šä¹‰é…ç½®ï¼Ÿ")
    print("1. ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆæ¨èï¼‰")
    print("2. è‡ªå®šä¹‰é…ç½®")
    
    while True:
        choice = input("è¯·é€‰æ‹© (1/2): ").strip()
        if choice in ['1', '2']:
            break
        print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")
    
    if choice == '1':
        config = SimulationConfig(**default_config)
        print(f"ä½¿ç”¨é»˜è®¤é…ç½®: å›¢é˜Ÿè§„æ¨¡={config.team_size}, æœ€å¤§è½®æ¬¡={config.max_rounds}")
    else:
        print("\nè¯·è¾“å…¥è‡ªå®šä¹‰é…ç½®ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤å€¼ï¼‰:")
        
        team_size = input(f"å›¢é˜Ÿè§„æ¨¡ (é»˜è®¤: {default_config['team_size']}): ").strip()
        team_size = int(team_size) if team_size else default_config['team_size']
        
        max_rounds = input(f"æœ€å¤§è½®æ¬¡ (é»˜è®¤: {default_config['max_rounds']}): ").strip()
        max_rounds = int(max_rounds) if max_rounds else default_config['max_rounds']
        
        task_complexity = input(f"ä»»åŠ¡å¤æ‚åº¦ (æ¨è: 2.0-5.0, é»˜è®¤: {default_config['task_complexity']}): ").strip()
        task_complexity = float(task_complexity) if task_complexity else default_config['task_complexity']
        
        random_seed = input(f"éšæœºç§å­ (é»˜è®¤: {default_config['random_seed']}): ").strip()
        random_seed = int(random_seed) if random_seed else default_config['random_seed']
        
        config = SimulationConfig(
            team_size=team_size,
            max_rounds=max_rounds,
            task_complexity=task_complexity,
            external_pressure=default_config['external_pressure'],
            random_seed=random_seed
        )
        
        print(f"è‡ªå®šä¹‰é…ç½®: å›¢é˜Ÿè§„æ¨¡={config.team_size}, æœ€å¤§è½®æ¬¡={config.max_rounds}")
    
    return config

def run_simulation(config: SimulationConfig):
    """è¿è¡Œä»¿çœŸå®éªŒ"""
    print("\n=== å¼€å§‹ä»¿çœŸå®éªŒ ===")
    
    # åˆ›å»ºä»¿çœŸå®ä¾‹
    sim = Simulation(config)
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    try:
        # è¿è¡Œå®éªŒ
        results = sim.run_experiment()
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"\nå®éªŒå®Œæˆï¼ç”¨æ—¶: {duration:.2f}ç§’")
        
        # ä¿å­˜ç»“æœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_filename = f"simulation_results_{timestamp}.json"
        sim.save_results(results_filename)
        
        return results, results_filename
        
    except Exception as e:
        print(f"å®éªŒè¿è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise

def analyze_results(results_filename: str):
    """åˆ†æå®éªŒç»“æœ"""
    print("\n=== å¼€å§‹ç»“æœåˆ†æ ===")
    
    try:
        # åŠ è½½ç»“æœ
        with open(results_filename, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer = ResultAnalyzer(results)
        
        # ç”ŸæˆæŠ¥å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = f"analysis_output_{timestamp}"
        analyzer.create_comprehensive_report(output_dir)
        
        print(f"åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨ç›®å½•: {output_dir}")
        
        return output_dir
        
    except Exception as e:
        print(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise

def print_quick_summary(results: dict):
    """æ‰“å°å¿«é€Ÿæ‘˜è¦"""
    print("\n=== å®éªŒç»“æœå¿«é€Ÿæ‘˜è¦ ===")
    
    try:
        comparison = results.get('comparison_data', {})
        overall = comparison.get('overall_performance', {})
        
        print(f"ğŸ† æ€»ä½“è¡¨ç°è·èƒœè€…: {overall.get('winner', 'N/A')} ç±»å‹é¢†å¯¼è€…")
        print(f"ğŸ“Š ç»¼åˆå¾—åˆ†: INFP={overall.get('infp_score', 0):.4f}, ESTP={overall.get('estp_score', 0):.4f}")
        print(f"ğŸ” å¾—åˆ†å·®å¼‚: {overall.get('score_difference', 0):.4f}")
        
        print("\nğŸ“ˆ å…³é”®æŒ‡æ ‡å¯¹æ¯”:")
        key_metrics = ['task_efficiency', 'avg_satisfaction', 'leader_influence', 'adoption_rate']
        metric_names = ['ä»»åŠ¡æ•ˆç‡', 'å›¢é˜Ÿæ»¡æ„åº¦', 'é¢†å¯¼å½±å“åŠ›', 'åˆ›æ„é‡‡çº³ç‡']
        
        for metric, name in zip(key_metrics, metric_names):
            if metric in comparison:
                data = comparison[metric]
                infp_val = data.get('infp', 0)
                estp_val = data.get('estp', 0)
                diff = data.get('difference', 0)
                
                winner = "INFP" if infp_val > estp_val else "ESTP"
                print(f"  {name}: {winner} é¢†å…ˆ (INFP={infp_val:.3f}, ESTP={estp_val:.3f}, å·®å¼‚={diff:.3f})")
        
        print("\nğŸ’¡ ä¸»è¦å‘ç°:")
        infp_metrics = results.get('infp_results', {}).get('final_metrics', {})
        estp_metrics = results.get('estp_results', {}).get('final_metrics', {})
        
        if infp_metrics.get('avg_satisfaction', 0) > estp_metrics.get('avg_satisfaction', 0):
            print("  â€¢ INFPé¢†å¯¼è€…åœ¨ç»´æŠ¤å›¢é˜Ÿæ»¡æ„åº¦æ–¹é¢è¡¨ç°æ›´ä¼˜")
        
        if estp_metrics.get('task_efficiency', 0) > infp_metrics.get('task_efficiency', 0):
            print("  â€¢ ESTPé¢†å¯¼è€…åœ¨ä»»åŠ¡æ‰§è¡Œæ•ˆç‡æ–¹é¢è¡¨ç°æ›´ä¼˜")
        
        if infp_metrics.get('adoption_rate', 0) > estp_metrics.get('adoption_rate', 0):
            print("  â€¢ INFPé¢†å¯¼è€…åœ¨ä¿ƒè¿›åˆ›æ–°æ–¹é¢è¡¨ç°æ›´ä¼˜")
        
        if estp_metrics.get('conflict_count', 0) < infp_metrics.get('conflict_count', 0):
            print("  â€¢ ESTPé¢†å¯¼è€…åœ¨å†²çªç®¡ç†æ–¹é¢è¡¨ç°æ›´ä¼˜")
        
    except Exception as e:
        print(f"ç”Ÿæˆæ‘˜è¦æ—¶å‡ºç°é”™è¯¯: {e}")
        print("è¯·æŸ¥çœ‹è¯¦ç»†çš„åˆ†ææŠ¥å‘Š")

def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='å¤šä¸»ä½“å»ºæ¨¡å®éªŒç³»ç»Ÿ')
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--analyze-only', type=str, help='ä»…åˆ†ææŒ‡å®šçš„ç»“æœæ–‡ä»¶')
    parser.add_argument('--quick-run', action='store_true', help='å¿«é€Ÿè¿è¡Œï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰')
    
    args = parser.parse_args()
    
    try:
        # ä»…åˆ†ææ¨¡å¼
        if args.analyze_only:
            print("è¿è¡Œæ¨¡å¼: ä»…åˆ†æå·²æœ‰ç»“æœ")
            output_dir = analyze_results(args.analyze_only)
            print(f"\nâœ… åˆ†æå®Œæˆï¼è¯·æŸ¥çœ‹ {output_dir} ç›®å½•ä¸­çš„ç»“æœ")
            return
        
        # å¿«é€Ÿè¿è¡Œæ¨¡å¼
        if args.quick_run:
            print("è¿è¡Œæ¨¡å¼: å¿«é€Ÿè¿è¡Œï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰")
            config = SimulationConfig(
                team_size=8,
                max_rounds=25,
                task_complexity=3.0,
                random_seed=42
            )
        else:
            # äº¤äº’å¼é…ç½®
            config = create_experiment_config()
        
        # è¿è¡Œä»¿çœŸ
        results, results_filename = run_simulation(config)
        
        # æ˜¾ç¤ºå¿«é€Ÿæ‘˜è¦
        print_quick_summary(results)
        
        # è¯¢é—®æ˜¯å¦è¿›è¡Œè¯¦ç»†åˆ†æ
        print("\næ˜¯å¦è¿›è¡Œè¯¦ç»†åˆ†æå¹¶ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Šï¼Ÿ")
        print("1. æ˜¯ï¼ˆæ¨èï¼Œç”Ÿæˆå®Œæ•´çš„å›¾è¡¨å’ŒæŠ¥å‘Šï¼‰")
        print("2. å¦ï¼ˆä»…ä¿å­˜åŸå§‹æ•°æ®ï¼‰")
        
        while True:
            choice = input("è¯·é€‰æ‹© (1/2): ").strip()
            if choice in ['1', '2']:
                break
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")
        
        if choice == '1':
            output_dir = analyze_results(results_filename)
            print(f"\nâœ… å®éªŒå’Œåˆ†æå…¨éƒ¨å®Œæˆï¼")
            print(f"ğŸ“ åŸå§‹æ•°æ®: {results_filename}")
            print(f"ğŸ“Š åˆ†ææŠ¥å‘Š: {output_dir}")
        else:
            print(f"\nâœ… ä»¿çœŸå®éªŒå®Œæˆï¼")
            print(f"ğŸ“ ç»“æœå·²ä¿å­˜: {results_filename}")
            print("ğŸ’¡ å¦‚éœ€åˆ†æï¼Œè¯·ä½¿ç”¨: python main.py --analyze-only " + results_filename)
        
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥é…ç½®å’Œè¾“å…¥æ•°æ®")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
